### pytorch

#### 1、反向传播前为什么要手动清空梯度

原因在于在PyTorch中，计算得到的梯度值会进行累加

2、归一化的作用

3、标签平滑的作用

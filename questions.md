### pytorch

#### 1、反向传播前为什么要手动清空梯度

原因在于在PyTorch中，计算得到的梯度值会进行累加

#### 2、归一化的作用

- 引入归一化，是由于在不同评价指标中，其量纲或是量纲单位往往不同，变化区间处于不同的数量级，若不进行归一化，可能导致某些指标被忽略，影响到数据分析的结果。为了消除特征数据之间的量纲影响，需要进行归一化处理，以解决特征指标之间的可比性。原始数据经过归一化处理后，各指标处于同一数量级，一边进行综合对比评价。
- 什么数据需要归一化
- 归一化的方法
- 归一化和标准化

#### 3、标签平滑的作用

- 在几乎所有的情况下，使用标签平滑训练可以产生更好的校准网络，从而更好地去泛化网路，最终对不可见的生产数据产生更准确的预测。因此，标签平滑应该是大多数深度学习训练的一部分。

- 平滑就是一定程度缩小label中min和max的差距，label平滑可以减小过拟合，提高模型的泛化能力。

#### 4、1*1的卷积

- 降维。比如，一张500*500且厚度depth为100的图片在20歌filter上做1\*1的卷积，那么结果的大小为500\*500\*20。
- 加入非线性。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励，提高网络的表达能力。

#### 5、ResNet中的BasicBlock与bottleneck

